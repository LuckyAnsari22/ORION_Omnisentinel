
/**
 * MULTI-MODAL AI FUSION
 * Combines Gemini Nano + MediaPipe + COCO-SSD for maximum accuracy
 * 
 * Reference: https://www.tensorflow.org/js/models
 */

import * as cocoSsd from '@tensorflow-models/coco-ssd';
import '@tensorflow/tfjs-backend-webgl';
import { geminiService } from './geminiService';
import { mediaPipeService } from './mediaPipeService';
import { IntelligentPromptEngine } from './advancedPrompts';

// Types
export interface FusedAnalysis {
    description: string;
    objects: FusedObject[];
    confidence: number;
    processingTime: number;
    sources: {
        gemini: number;
        mediaPipe: number;
        coco: number;
    };
}

export interface FusedObject {
    name: string;
    confidence: number;
    boundingBox: BoundingBox;
    position: SpatialDescription;
    sources: string[];
}

export interface SpatialDescription {
    clockPosition: number;
    heightLevel: string;
    distance: string;
    fullDescription: string;
    reachable: boolean;
}

export interface BoundingBox {
    x: number;
    y: number;
    width: number;
    height: number;
}

export interface DetectedObject {
    name: string;
    confidence: number;
    boundingBox: BoundingBox;
    source: string;
}

export class IntelligenceFusionEngine {
    // private geminiService: any; // Imported directly
    // private mediaPipeService: any; // Imported directly
    private cocoModel: cocoSsd.ObjectDetection | null = null;
    private initialized: boolean = false;

    async initialize(): Promise<void> {
        console.log('üß† Initializing Multi-Modal Intelligence...');

        // Load COCO-SSD for object detection
        try {
            this.cocoModel = await cocoSsd.load({
                base: 'mobilenet_v2' // Faster than lite_mobilenet_v2
            });
            console.log('‚úÖ COCO-SSD Ready');
        } catch (e) {
            console.warn('‚ö†Ô∏è COCO-SSD Failed to load', e);
        }

        this.initialized = true;
        console.log('‚úÖ Intelligence Fusion Ready');
    }

    /**
     * FUSION ANALYSIS - Combines 3 AI systems
     * Returns most accurate result with confidence scoring
     */
    async analyzeSceneFusion(imageElement: HTMLImageElement | HTMLVideoElement, mode: 'description' | 'text' | 'object' | 'color' | 'navigation' = 'description'): Promise<FusedAnalysis> {
        if (!this.initialized) {
            await this.initialize();
        }

        const startTime = performance.now();
        let imageDataUrl = '';

        if (imageElement instanceof HTMLVideoElement) {
            const canvas = document.createElement('canvas');
            canvas.width = imageElement.videoWidth;
            canvas.height = imageElement.videoHeight;
            canvas.getContext('2d')?.drawImage(imageElement, 0, 0);
            imageDataUrl = canvas.toDataURL('image/jpeg');
        } else {
            imageDataUrl = imageElement.src;
        }

        // MODE SWITCHING LOGIC
        if (mode === 'text') {
            const textResult = await geminiService.readText(imageDataUrl);
            return {
                description: textResult,
                objects: [],
                confidence: 1.0,
                processingTime: performance.now() - startTime,
                sources: { gemini: 1, mediaPipe: 0, coco: 0 }
            };
        }

        if (mode === 'color') {
            const colorResult = await geminiService.identifyColors(imageDataUrl);
            return {
                description: colorResult,
                objects: [],
                confidence: 1.0,
                processingTime: performance.now() - startTime,
                sources: { gemini: 1, mediaPipe: 0, coco: 0 }
            };
        }

        if (mode === 'navigation') {
            // For navigation, we want specific "path finding" prompts
            const navResult = await geminiService.analyzeScene(imageDataUrl, "Analyze specifically for safe navigation. Is the path clear? detailed hazards? Directions?");
            // We can still try to fuse objects for hazards in future, but for now focus on the prompt.
            return {
                description: navResult,
                objects: [],
                confidence: 1.0,
                processingTime: performance.now() - startTime,
                sources: { gemini: 1, mediaPipe: 0, coco: 0 }
            };
        }

        // DEFAULT: DESCRIPTION / FUSION MODE
        const [geminiResult, mediaPipeResult, cocoResult] = await Promise.all([
            this.runGeminiAnalysis(imageDataUrl),
            this.runMediaPipeAnalysis(imageElement),
            this.runCocoAnalysis(imageElement)
        ]);

        // FUSION ALGORITHM: Combine results with confidence weighting
        const fusedObjects = this.fuseObjectDetections(
            mediaPipeResult.objects,
            cocoResult.objects
        );

        // Enhance Gemini description with precise object positions
        const enhancedDescription = this.enhanceDescription(
            geminiResult.description,
            fusedObjects
        );

        const processingTime = performance.now() - startTime;
        console.log(`‚ö° Fusion analysis completed in ${processingTime.toFixed(0)}ms`);

        // Add to context memory
        IntelligentPromptEngine.addContext('scene', enhancedDescription);

        return {
            description: enhancedDescription,
            objects: fusedObjects,
            confidence: this.calculateOverallConfidence(fusedObjects),
            processingTime,
            sources: {
                gemini: geminiResult.confidence,
                mediaPipe: mediaPipeResult.confidence,
                coco: cocoResult.confidence
            }
        };
    }

    /**
     * OBJECT FUSION - Merges detections from multiple sources
     * Uses Non-Maximum Suppression (NMS) to eliminate duplicates
     */
    private fuseObjectDetections(
        mediaPipeObjects: DetectedObject[],
        cocoObjects: DetectedObject[]
    ): FusedObject[] {
        const allObjects = [...mediaPipeObjects, ...cocoObjects];

        // Group similar objects (IoU threshold = 0.5)
        const groups = this.groupOverlappingObjects(allObjects, 0.5);

        // For each group, pick highest confidence or merge
        return groups.map(group => {
            //   if (group.length === 1) return { ...group[0], position: this.calculateSpatialDescription(group[0].boundingBox), sources: [group[0].source] };

            // MERGE STRATEGY: Average positions, max confidence, consensus name
            const consensusName = this.getConsensusName(group);
            const maxConfidence = Math.max(...group.map(o => o.confidence));
            const avgBoundingBox = this.averageBoundingBoxes(group.map(o => o.boundingBox));
            const spatialDesc = this.calculateSpatialDescription(avgBoundingBox);

            // Add to context memory
            IntelligentPromptEngine.addContext('object', consensusName, spatialDesc.fullDescription);

            return {
                name: consensusName,
                confidence: maxConfidence,
                boundingBox: avgBoundingBox,
                position: spatialDesc,
                sources: group.map(o => o.source).filter((v, i, a) => a.indexOf(v) === i)
            };
        });
    }

    /**
     * SPATIAL INTELLIGENCE - Ultra-precise position calculation
     */
    private calculateSpatialDescription(bbox: BoundingBox): SpatialDescription {
        const centerX = bbox.x + bbox.width / 2;
        const centerY = bbox.y + bbox.height / 2;

        // Clock position (12 = top/front, 3 = right, 6 = back, 9 = left)
        const clockPosition = this.getClockPosition(centerX, centerY);

        // Height level
        const heightLevel = this.getHeightLevel(centerY);

        // Distance estimation (based on bounding box size)
        const distance = this.estimateDistance(bbox.width * bbox.height);

        // Detailed position string
        const position = `${clockPosition} o'clock, ${heightLevel} level, ${distance}`;

        return {
            clockPosition,
            heightLevel,
            distance,
            fullDescription: position,
            reachable: distance.includes('within reach') || distance.includes('3 feet')
        };
    }

    private getClockPosition(x: number, y: number): number {
        // MediaPipe/TFJS coordinates are normalized 0-1 usually? Or pixel?
        // TFJS COCO-SSD returns pixel coords usually? No, it returns [x,y,w,h].
        // MediaPipe returns normalized. 
        // We need to normalize if pixel. Assuming normalized [0,1] for calculation simplicity here.
        // NOTE: This logic assumes 0-1.
        // If input is not 0-1, we need to normalize.
        // Let's assume passed BBoxes are normalized for spatial calc. I'll ensure normalization in wrappers.

        // Center is 0.5, 0.5
        // Angle from center
        // y is inverted in screen coords? No, 0 is top.

        const dx = x - 0.5;
        const dy = y - 0.5;
        // Atan2(y, x). 
        // 12 o clock is up (negative y). 
        // Atan2(0, 1) = 0 (Right, 3 o'clock).
        // Atan2(1, 0) = PI/2 (Down, 6 o'clock).
        // Atan2(0, -1) = PI (Left, 9 o'clock)
        // Atan2(-1, 0) = -PI/2 (Up, 12 o'clock).

        let angle = Math.atan2(dy, dx) * (180 / Math.PI);
        // Map to clock. 
        // -90 -> 12
        // 0 -> 3
        // 90 -> 6
        // 180/-180 -> 9

        // Convert to 1-12
        const clockOffset = angle + 90; // -90 becomes 0.
        // 0 (12) ... 90 (3) ... 180 (6) ... 270 (9)
        const positiveAngle = (clockOffset + 360) % 360;
        const hour = Math.round(positiveAngle / 30);
        return hour === 0 ? 12 : hour;
    }

    private getHeightLevel(y: number): string {
        // 0 is top, 1 is bottom
        if (y < 0.3) return 'high/head level';
        if (y < 0.6) return 'mid/waist level';
        return 'low/floor level';
    }

    private estimateDistance(area: number): string {
        // Heuristic: larger objects = closer
        // Area 0-1
        if (area > 0.4) return 'very close / within reach';
        if (area > 0.15) return 'near / about 3-5 feet';
        return 'further away / across room';
    }

    /**
     * DESCRIPTION ENHANCEMENT - Injects precise positions into Gemini's description
     */
    private enhanceDescription(
        geminiDescription: string,
        fusedObjects: FusedObject[]
    ): string {
        // Parse Gemini's description and inject precision
        let enhanced = geminiDescription;

        if (fusedObjects.length === 0) return enhanced;

        enhanced += "\n\nPrecision details:";

        // For each detected object, add/update position precision
        fusedObjects.forEach(obj => {
            enhanced += `\n- ${obj.name}: ${obj.position.fullDescription}`;
        });

        return enhanced;
    }

    /**
     * CONFIDENCE SCORING - Overall system confidence
     */
    private calculateOverallConfidence(objects: FusedObject[]): number {
        if (objects.length === 0) return 0.5; // Medium confidence for empty scene

        // Weighted average of object confidences
        const avgConfidence = objects.reduce((sum, obj) => sum + obj.confidence, 0) / objects.length;

        // Bonus for multi-source confirmation
        const multiSourceBonus = objects.filter(o => o.sources.length > 1).length / objects.length;

        return Math.min(avgConfidence + (multiSourceBonus * 0.1), 1.0);
    }

    // Helper methods
    private groupOverlappingObjects(objects: DetectedObject[], iouThreshold: number): DetectedObject[][] {
        // Simple grouping 
        const groups: DetectedObject[][] = [];
        const used = new Set<number>();

        for (let i = 0; i < objects.length; i++) {
            if (used.has(i)) continue;
            const group = [objects[i]];
            used.add(i);

            for (let j = i + 1; j < objects.length; j++) {
                if (used.has(j)) continue;
                // Calculate IoU
                if (this.calculateIoU(objects[i].boundingBox, objects[j].boundingBox) > iouThreshold) {
                    group.push(objects[j]);
                    used.add(j);
                }
            }
            groups.push(group);
        }

        return groups;
    }

    private calculateIoU(box1: BoundingBox, box2: BoundingBox): number {
        // Intersection
        const x1 = Math.max(box1.x, box2.x);
        const y1 = Math.max(box1.y, box2.y);
        const x2 = Math.min(box1.x + box1.width, box2.x + box2.width);
        const y2 = Math.min(box1.y + box1.height, box2.y + box2.height);

        if (x2 < x1 || y2 < y1) return 0.0;

        const intersection = (x2 - x1) * (y2 - y1);
        const outputArea1 = box1.width * box1.height;
        const outputArea2 = box2.width * box2.height;

        return intersection / (outputArea1 + outputArea2 - intersection);
    }

    private getConsensusName(group: DetectedObject[]): string {
        // Prefer COCO names as they are standard, or MediaPipe if confident
        // Just pick the one with highest confidence
        const best = group.reduce((prev, current) => (prev.confidence > current.confidence) ? prev : current);
        return best.name;
    }

    private averageBoundingBoxes(boxes: BoundingBox[]): BoundingBox {
        const count = boxes.length;
        return {
            x: boxes.reduce((sum, b) => sum + b.x, 0) / count,
            y: boxes.reduce((sum, b) => sum + b.y, 0) / count,
            width: boxes.reduce((sum, b) => sum + b.width, 0) / count,
            height: boxes.reduce((sum, b) => sum + b.height, 0) / count
        };
    }

    private async runGeminiAnalysis(imageData: string): Promise<any> {
        // Use the IntelligentPromptEngine to generate the prompt
        const contextStr = IntelligentPromptEngine.getRecentContext();
        const prompt = IntelligentPromptEngine.buildScenePrompt(imageData, { previousScene: contextStr });

        // Call existing service
        const description = await geminiService.analyzeScene(imageData, prompt); // Pass the advanced prompt as context/override?
        // Note: geminiService.analyzeScene signature is (imageData, context, detections).
        // The previous implementation used the context as a suffix.
        // We might need to adjust geminiService to accept the FULL prompt if we really want to use the AdvancedPromptEngine.
        // Or we rely on the intelligent fallback inside geminiService if offline.
        // If online, geminiService uses the prompt we passed.

        // Let's pass the prompt as the 'context' for now, assuming geminiService preserves it.

        return { description: description, confidence: 0.9 };
    }

    private async runMediaPipeAnalysis(image: HTMLImageElement | HTMLVideoElement): Promise<{ objects: DetectedObject[], confidence: number }> {
        // mediaPipeService.detectObjects returns custom objects.
        // We need to map them to DetectedObject interface here.
        try {
            // any cast because MP service expects specific types but usually works with standard HTML media
            const results = await mediaPipeService.detectObjects(image as any);
            const mapped: DetectedObject[] = results.map((r: any) => ({
                name: r.name || r.categoryName || 'object',
                confidence: r.confidence || r.score || 0.5,
                // MediaPipe bbox might be different format?
                // Helper says: { originX, originY, width, height } usually from MP tasks
                boundingBox: {
                    x: r.boundingBox?.originX ?? r.boundingBox?.x ?? 0,
                    y: r.boundingBox?.originY ?? r.boundingBox?.y ?? 0,
                    width: r.boundingBox?.width ?? 0,
                    height: r.boundingBox?.height ?? 0
                },
                source: 'mediapipe'
            }));
            return { objects: mapped, confidence: 0.85 };
        } catch (e) {
            return { objects: [], confidence: 0 };
        }
    }

    private async runCocoAnalysis(image: HTMLImageElement | HTMLVideoElement): Promise<{ objects: DetectedObject[], confidence: number }> {
        if (!this.cocoModel) return { objects: [], confidence: 0 };

        try {
            const predictions = await this.cocoModel.detect(image);

            // Normalize coordinates if necessary?
            // COCO-SSD returns [x, y, width, height] in pixels.
            // We need to normalize to 0-1 for our fusion logic (spatial calc) if we assume 0-1.
            // Let's get image dims.
            let width = 1;
            let height = 1;
            if (image instanceof HTMLImageElement) {
                width = image.naturalWidth || image.width;
                height = image.naturalHeight || image.height;
            } else if (image instanceof HTMLVideoElement) {
                width = image.videoWidth;
                height = image.videoHeight;
            }

            return {
                objects: predictions.map(pred => ({
                    name: pred.class,
                    confidence: pred.score,
                    boundingBox: {
                        x: pred.bbox[0] / width,
                        y: pred.bbox[1] / height,
                        width: pred.bbox[2] / width,
                        height: pred.bbox[3] / height
                    },
                    source: 'coco-ssd'
                })),
                confidence: 0.8
            };
        } catch (e) {
            return { objects: [], confidence: 0 };
        }
    }
}

export const intelligenceFusionEngine = new IntelligenceFusionEngine();
